"""This is the file for master node"""


import argparse
import multiprocessing

from loguru import logger
import math
import os

from map_worker import Mapper
from reduce_worker import Reducer


class Master:
    """Master node class"""

    def __init__(self, input_data, output_data, n_map, n_reduce):
        self.input_data = input_data
        self.output_data = output_data
        self.n_map = n_map
        self.n_reduce = n_reduce
        self.mappers = []
        self.reducers = []
        logger.debug("Master node initialized. Starting child nodes.")
        self.initialize_nodes()
        logger.debug("Initializing complete.")

    def run(self):
        logger.debug("Starting Input Split.")
        self.input_split()
        #TODO: Spawn processes for mappers
        logger.debug("Starting map phase.")
        self.map()
        logger.debug("Map phase complete. Starting partition phase.")
        self.partition()
        logger.debug("Partition phase complete. Starting reduce phase.")
        self.reduce()
        logger.debug("Reduce phase complete. Job complete.")

    def initialize_nodes(self):
        """Initialize and register the mappers"""
        for i in range(self.n_map):
            p = multiprocessing.Process(target=Mapper, args=(None))
            p.start()
            self.mappers.append(p)

        """Initialize and register the reducers"""
        for i in range(self.n_reduce):
            p = multiprocessing.Process(target=Reducer, args=(None))
            p.start()
            self.reducers.append(p)

    def input_split(self):
        """For simplicity, you may assume that the input data
        consists of multiple data files and each file is
        processed by a separate mapper.
        """
        input_files = os.listdir(self.input_data)
        files_per_mapper = math.ceil(len(os.listdir(self.input_data)) / self.n_map)
        self.partitions = [input_files[i:i+files_per_mapper] for i in range(0, len(input_files), files_per_mapper)]

    # key -> document name, value -> document content  || figure out how to go about map function parameters
    def map(self, key, value, input_files):
        """Map function to each input split to generate
        intermediate key-value pairs. The Map function takes a
        key-value pair as input and produces a set of
        intermediate key-value pairs as output. The output of
        each Map function should be written to a file in the
        mapper's directory on the local file system. Note
        that each mapper will be run as a different process.
        """
        for input_file in input_files:
            with open(os.path.join(self.input_data, input_file), 'r') as f:
                # Read the input data file
                input_data = f.read()
                lines = input_data.split('\n')

                words = []
                for line in lines:
                    line_words = line.split()
                    words.extend(line_words)

                intermediate_key_values = set()
                #TODO: Check whether the frequency will be updated in here
                for word in words:
                    intermediate_key_values.add((word, '1'))

                # Write the intermediate key-value pairs to a file in the mapper's directory
                output_file = os.path.join(self.output_data, input_file)
                with open(output_file, 'w') as f:
                    for intermediate_key, intermediate_value in intermediate_key_values:
                        f.write('{}\t{}\n'.format(intermediate_key, intermediate_value))

    def partition(self):
        """write a function that takes the list of key-value
        pairs generated by the Map function and partitions them
        into a set of smaller partitions. The partitioning
        function should ensure that all key-value pairs
        with the same key are sent to the same partition.
        Each partition is then picked up by a specific reducer
        during shuffling and sorting.
        """
        pass


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", help="Input data directory", required=True)
    parser.add_argument("--output", help="Output data directory", required=True)
    parser.add_argument("--n_map", help="Number of mappers", required=True)
    parser.add_argument("--n_reduce", help="Number of reducers", required=True)
    args = parser.parse_args()

    master = Master(args.input, args.output, args.n_map, args.n_reduce)
    master.run()
